{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project Analysis - Cohort Analysis & Layer Cake Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5>1. Proposal</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In 21th century, customers' data are becoming more and more essential to SaaS companies, they are able to provide the most appropriate service to customers based on them. As cohort analysis gives user an understanding of the why, how, and when of customer's actions that helps user to make decisions, we want to conduct several cohort analysis on the top 3 most frequently represented countries on the list to see whether there are any correlations between them from our datasets with card paid or refunded for customer in 2020 from different countries. If so, this should answer the question that why every SaaS Company needs to be doing with cohort analysis. For further progress, we want to conduct a cohort layer cake chart with no geographic seperation. .... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5>2. Retrieve Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets: customer details in 2020: https://github.com/shy1213/Project/blob/main/query_result_2021-05-18T03%2046%2057.095586Z%20(1).csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AE',\n",
       " 'BE',\n",
       " 'CD',\n",
       " 'CN',\n",
       " 'KE',\n",
       " 'KW',\n",
       " 'LV',\n",
       " 'NG',\n",
       " 'TW',\n",
       " 'DK',\n",
       " 'JP',\n",
       " 'LT',\n",
       " 'NZ',\n",
       " 'ES',\n",
       " 'IT',\n",
       " 'RU',\n",
       " 'HK',\n",
       " 'MT',\n",
       " 'PL',\n",
       " 'IN',\n",
       " 'EE',\n",
       " 'IE',\n",
       " 'NL',\n",
       " 'UA',\n",
       " 'IL',\n",
       " 'FR',\n",
       " 'DE',\n",
       " 'SG',\n",
       " 'FI',\n",
       " 'GB',\n",
       " 'CA',\n",
       " 'AU',\n",
       " 'US',\n",
       " nan]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv('/Users/shy/Downloads/customer.csv')\n",
    "\n",
    "appear_times = {}\n",
    "for country in data_set['card__country']:\n",
    "    if country not in appear_times:\n",
    "        appear_times[country] = 1\n",
    "    else:\n",
    "        appear_times[country] += 1\n",
    "\n",
    "def sort(x):\n",
    "    items = x.items()\n",
    "    back = [[cha[1], cha[0]] for cha in items]\n",
    "    back.sort()\n",
    "    return [back[i][1] for i in range(0, len(back))]\n",
    "\n",
    "sort(appear_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we retrieve the top 3 countries which are US, AU an CA. Then we are able to conduct our three seperated cohort analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5>2.1 US Cohort Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_US = pd.read_csv('/Users/shy/Downloads/customer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_US = data_set_US.loc[data_set_US['card__country'] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_US['created'] = data_set_US['created'].str.replace('T', ' ')\n",
    "data_set_US['created'] = data_set_US['created'].str.replace('Z', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
